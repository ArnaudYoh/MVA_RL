{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rly7ZGiyUKJ6"
   },
   "source": [
    "# Exploration in Linear Bandits\n",
    "\n",
    "The objective of this part is to implement and compare the following strategies for linear bandits:\n",
    "\n",
    "[Optimism in the Face of Uncertainty (LinUCB/OFUL)](https://papers.nips.cc/paper/4417-improved-algorithms-for-linear-stochastic-bandits.pdf)\n",
    "\n",
    "[Thompson Sampling](https://projecteuclid.org/euclid.ejs/1513306870)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "infCxpaRA0XC"
   },
   "source": [
    "## Linear bandit\n",
    "We consider the standard linear bandit setting. At each time $t$, the agent selects an arm $a_t \\in A$ and observes a reward\n",
    "$$\n",
    "r_{a}^t = \\langle \\theta^\\star, \\phi_a^t \\rangle + \\eta_a^t := \\mu_a^t + \\eta_a^t\n",
    "$$\n",
    "where $\\theta^{\\star}¬†\\in \\mathbb{R}^{d}$ is a parameter vector, $\\phi_{a}^t \\in \\mathbb{R}^{d} $ are the features of arm $a$ at time $t$, and $\\eta_{a}^{t}$ is a zero-mean  $\\sigma^2$-subgaussian noise. \n",
    "\n",
    "When the features correspond to the canonical basis, this formulation reduces to multi-armed bandit (MAB) with $d$ arms. In the more general case, the features may depend on a context $x_t$, so that $\\phi_a^t = \\phi(x_t, a)$ denotes the feature vector of a context-action pair $(x_t, a)$ and the resulting setting is the so-called linear contextual bandit.\n",
    "\n",
    "We rely on the following standard assumption on the features and the unknown parameter $\\theta^\\star$.\n",
    "\n",
    "**Assumption.** There exist $B,D \\geq 0$, such that $\\|\\theta^\\star\\|_2 \\leq B$, $\\|\\phi_a^t\\| \\leq D$, and $\\langle \\theta^\\star, \\phi_a^t \\rangle \\in [0,1]$, for all $t$ and $a$.\n",
    "\n",
    "Given a finite horizon $n$, the performance of the agent is measured by its (pseudo)-*regret*:\n",
    "$$\n",
    "        %R(n) = n \\mu^{\\star} - \\sum_{t=1}^n \\mu_{a_t} = \\sum_{i=1}^K T_i(n) \\Delta_i, \n",
    "        R(n) = \\sum_{t=1}^n \\langle \\theta^\\star, \\phi_{a^\\star}^t \\rangle - \\langle \\theta^\\star, \\phi_{a_t}^t \\rangle ,\n",
    "$$\n",
    "where $a^{\\star}_{t} \\in \\arg\\max_{a} \\langle \\theta^\\star, \\phi_{a}^t \\rangle$ is the optimal action at time $t$.\n",
    "\n",
    "**We consider the simple linear bandit setting:** $\\phi_a^t = \\phi_a, \\; \\forall t$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SlwPdLAwUWfI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mvarl_hands_on'...\n",
      "remote: Enumerating objects: 39, done.\u001b[K\n",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 39 (delta 14), reused 37 (delta 12), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (39/39), done.\n",
      "cliffwalk.py  discretization.py  frozen_lake.py  test_env.py\n",
      "coldstart.py  finite_env.py\t gridworld.py\n"
     ]
    }
   ],
   "source": [
    "!rm -rf mvarl_hands_on/\n",
    "!git clone https://github.com/rlgammazero/mvarl_hands_on.git\n",
    "!cd mvarl_hands_on/ && git fetch\n",
    "!ls mvarl_hands_on/utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWQOcbHbUKJ8"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './mvarl_hands_on/utils')\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from coldstart import ColdStartFromDataset\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78oy9izEUKKA"
   },
   "source": [
    "#### Jester Jokes Dataset (Dense subset of 40 jokes)\n",
    "\n",
    "Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling\n",
    "\n",
    "Download the data at: https://storage.googleapis.com/bandits_datasets/jester_data_40jokes_19181users.npy\n",
    "\n",
    "We performed a matrix factorization of the ratings (after filtering over users and jokes). This provides features for the arms and users, the reward (ie rating) is the dot product between the arm and user features (we make it stochastic by adding Gaussian noise). We consider a cold start problem where the user is randomly selected at the beginning of the repetition and the agent has to learn the best arm to recommend. When an arm is selected by the algorithm, its reward is computed as the dot product between the arm and user features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HW1YAyl1UKKB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-30 00:14:35--  https://storage.googleapis.com/bandits_datasets/jester_data_40jokes_19181users.npy\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:4007:815::2010, 216.58.204.144\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:4007:815::2010|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6138000 (5.9M) [application/octet-stream]\n",
      "Saving to: ‚Äòjester_data_40jokes_19181users.npy‚Äô\n",
      "\n",
      "jester_data_40jokes 100%[===================>]   5.85M  10.1MB/s    in 0.6s    \n",
      "\n",
      "2019-12-30 00:14:36 (10.1 MB/s) - ‚Äòjester_data_40jokes_19181users.npy‚Äô saved [6138000/6138000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bandits_datasets/jester_data_40jokes_19181users.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZsqokZKUKKD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: (19181, 35)\n",
      "Vt: (35, 40)\n",
      "#features: 35\n",
      "#arms: 40\n"
     ]
    }
   ],
   "source": [
    "M = np.load('jester_data_40jokes_19181users.npy')\n",
    "M = M / 10\n",
    "K = 35\n",
    "U, s, Vt = svds(M, k = K)\n",
    "s=np.diag(s)\n",
    "U = np.dot(U,s)\n",
    "print('U: {}'.format(U.shape))\n",
    "print('Vt: {}'.format(Vt.shape))\n",
    "print('#features: {}'.format(Vt.shape[0]))\n",
    "print('#arms: {}'.format(Vt.shape[1]))\n",
    "np.savetxt('U_jester.csv', U, delimiter=',') \n",
    "np.savetxt('Vt_jester.csv', Vt, delimiter=',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VmQdkpc-UKKF"
   },
   "source": [
    "Create the coldstart model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDXGgf-HUKKF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current config is:\n",
      "{'arm_csvfile': '/home/naunauyoh/PycharmProjects/MVA_RL/Vt_jester.csv',\n",
      " 'noise_std': 0.1,\n",
      " 'random_state': 1235,\n",
      " 'user_csvfile': '/home/naunauyoh/PycharmProjects/MVA_RL/U_jester.csv',\n",
      " 'user_subset': [0, 44, 88, 133, 177, 222, 266, 311, 355, 400]}\n"
     ]
    }
   ],
   "source": [
    "seed = 1235\n",
    "user_subset = np.linspace(0, 400, 10).astype(int).tolist()\n",
    "arm_csvfile = os.path.abspath('Vt_jester.csv')\n",
    "user_csvfile = os.path.abspath('U_jester.csv')\n",
    "noise_std = 0.1\n",
    "\n",
    "config_cs = {\n",
    "    'arm_csvfile': arm_csvfile,\n",
    "    'user_csvfile': user_csvfile,\n",
    "    'random_state': seed,\n",
    "    'user_subset': user_subset,\n",
    "    'noise_std': noise_std\n",
    "}\n",
    "\n",
    "print(\"Current config is:\")\n",
    "pprint(config_cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjPeT4LLUKKH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The new user arriving to the system is user # 133\n",
      "\n",
      "Theta*:  [ 0.07360712  0.17734693  0.20495631 -0.22209593  0.19274253 -0.18410772\n",
      "  0.11715996 -0.46113109 -0.07918465  0.06932272  0.08971403 -0.17425277\n",
      "  0.22851053  0.16756964 -0.9522754   0.33699145  0.3933289  -0.74392791\n",
      " -0.26068602  0.63669768 -0.24925958  0.84903929 -0.04273235 -0.62347351\n",
      " -0.1563364  -0.54413666  0.48877408 -0.45984457 -0.86347719  0.21857714\n",
      " -0.36691055 -0.73139386 -1.43376962 -0.03908683 -1.71844609]\n",
      "\n",
      "Means:  [0.80575473 0.1709222  0.40801812 0.67453197 0.03911792 0.07580014\n",
      " 0.74331481 0.39452305 0.58721524 1.         0.96657887 0.65363789\n",
      " 0.48448818 0.13126515 0.73118925 0.78475723 0.84698373 0.73243179\n",
      " 0.69016416 0.20050761 0.91706563 0.53946859 0.67640884 0.05161643\n",
      " 0.76192058 0.51896502 0.04415654 0.         0.76867243 0.33779268\n",
      " 0.08463928 0.05049376 0.49854492 0.69503763 0.12060601 0.14961957\n",
      " 0.08393364 0.55350756 0.67109645 0.85149357]\n",
      "\n",
      "Theta bound:  3.3428890242516553\n"
     ]
    }
   ],
   "source": [
    "noise = 0.2\n",
    "random_state = 312\n",
    "model = ColdStartFromDataset(**config_cs)\n",
    "print(\"\\nThe new user arriving to the system is user #\", model.theta_idx)\n",
    "print(\"\\nTheta*: \", model.theta)\n",
    "means = np.dot(model.features, model.theta)\n",
    "print(\"\\nMeans: \", means)\n",
    "theta_bound = np.linalg.norm(model.theta, 2)\n",
    "print(\"\\nTheta bound: \", theta_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6KUmWBFlUKKJ"
   },
   "source": [
    "**Question 1**: implement LinUCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G45BzTW_J4Gr"
   },
   "source": [
    "### LinUCB / OFUL\n",
    "See the slides!\n",
    "\n",
    "Note that it is not necessary to invert the matrix $A_t$ at each round. Since $A_t$ is obtained from a rank-1 update of $A_{t-1}$, it is possible to use Sherman‚ÄìMorrison formula to build directly $A_t^{-1}$.\n",
    "\n",
    "Suppose $ùê¥$ be a nonsingular $n\\times n$ matrix and $\\mathbf{u}, \\mathbf{v}$ be vectors. Then\n",
    "$$\n",
    "(A+\\mathbf{u}\\mathbf{v}^T)^{-1} = A^{-1} - \\frac{A^{-1}\\mathbf{u}\\mathbf{v}^TA^{-1}}{1+\\mathbf{v}^TA^{-1}\\mathbf{u}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AxRC2xoAUKKJ"
   },
   "outputs": [],
   "source": [
    "class OFUL:\n",
    "    def __init__(self, arm_features, reg_factor, delta,\n",
    "                 bound_theta, noise_std):\n",
    "        \n",
    "        self.arm_features = arm_features\n",
    "        self.reg_factor = reg_factor\n",
    "        self.delta = delta\n",
    "        self.iteration = 0\n",
    "        self.bound_theta = bound_theta\n",
    "        self.bound_features = np.max(np.sqrt(np.sum(np.abs(arm_features) ** 2, axis=1)))\n",
    "        self.noise_std = noise_std\n",
    "        \n",
    "        self.A = np.eye(self.n_features)\n",
    "        self.A_inv = np.eye(self.n_features)\n",
    "        self.b = np.zeros((self.n_features, 1))\n",
    "        self.theta = np.zeros((self.n_features, 1))\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    @property\n",
    "    def n_actions(self):\n",
    "        return self.arm_features.shape[0]\n",
    "\n",
    "    @property\n",
    "    def n_features(self):\n",
    "        return self.arm_features.shape[1]\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Return the internal estimates\n",
    "        Not sure about the naming of this function ... \n",
    "        \"\"\"\n",
    "        estimates = []\n",
    "        for arm_feature in arm_features:\n",
    "            estimates.append(arm_feature.dot(self.theta))\n",
    "        \n",
    "        return np.array(estimates)\n",
    "        \n",
    "    def alpha(self, n_samples):\n",
    "        # TODO remove the n_samples (?) as it seems equivalent to self.iteration\n",
    "        return self.noise_std * np.sqrt(self.n_features * \n",
    "                                        np.log((1 + self.iteration * self.bound_features / self.reg_factor) / self.delta)) + \\\n",
    "                                np.sqrt(self.reg_factor) * self.bound_theta\n",
    "                        \n",
    "        \n",
    "    def sample_action(self):\n",
    "        \"\"\"Return the action to play based on current estimates\n",
    "        \"\"\"\n",
    "        action = None\n",
    "        val = None\n",
    "        alpha = self.alpha()\n",
    "        estimates = self.reset()\n",
    "        for i, estimate in enumerate(estimates):\n",
    "            B = estimate + alpha * np.sqrt(self.arm_features[i].dot(self.A_inv).dot(self.arm_features[i]))\n",
    "            if action is None or val < B:\n",
    "                action = i\n",
    "                val = B\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def update(self, a_t, r_t):\n",
    "        \"\"\"Update the estimates of the model\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        a_t: int\n",
    "            The action played at the current episode\n",
    "        r_t: float\n",
    "            The reward associated to action a_t\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        none\n",
    "        \"\"\"\n",
    "        features = self.arm_features[a_t]\n",
    "        self.A += np.outer(features,features)\n",
    "        \n",
    "        self.b += r_t*features\n",
    "        \n",
    "        self.A_inv = self.A_inv - self.A_inv.dot(np.outer(features,features)).dot(self.A_inv) / \\\n",
    "            (1 + features.dot(self.A_inv).dot(features))\n",
    "        \n",
    "        self.theta = self.A_inv.dot(self.b)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OtwYcKlrK6UP"
   },
   "source": [
    "**Question 2:** implement LinearTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9xl29-B3MEOC"
   },
   "source": [
    "Let $A_t$ be the design matrix, $\\theta_t$ the estimate of $\\theta^\\star$ and $\\beta_t$ the confidence interval built by LinUCB. Then, at every time step t,  LinearTS simply generates\n",
    "a sample $\\tilde{\\theta}_t$ from the distribution $\\mathcal{N}(\\widehat{\\theta}_t, \\omega_t \\alpha_t^2 A_t^{-1})$.\n",
    "\n",
    "LinearTS\n",
    "\n",
    "For $t=1, \\ldots, T$\n",
    "> $\\tilde{\\theta}_t \\sim \\mathcal{N}(\\widehat{\\theta}_t, \\omega_t \\alpha_t^2 A_t^{-1})$\n",
    ">\n",
    "> $a_t \\in \\arg\\max_{a \\in \\mathcal{A}_t}  \\langle \\tilde{\\theta}_t, \\phi_{a} \\rangle$\n",
    ">\n",
    "> observe reward $r_t$\n",
    "\n",
    "TS is requires to draw $\\tilde{\\theta}_t$ from a distribution over-sampling by a factor $\\sqrt{d}$ the ellipsoid constructed by OFUL (i.e., $\\omega_t = d$). This is required to prove that LinearTS is optimistic with a fix probability. This is necessary to prove the frequentist regret of TS. The regret of TS is worse than the one of LinUCB by a factor $\\sqrt{d}$ (i.e., $\\widetilde{O}(d^{3/2}\\sqrt{T})$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTJh0yqgUKKM"
   },
   "outputs": [],
   "source": [
    "class LinearTS(OFUL):\n",
    "    def __init__(self, arm_features, reg_factor, delta,\n",
    "                 bound_theta, noise_std):\n",
    "        super(LinearTS, self).__init__(arm_features, reg_factor, delta,\n",
    "                 bound_theta, noise_std)\n",
    "        self.alpha = \n",
    "        \n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKERx2_UUKKN"
   },
   "source": [
    "**Question 3**: run the algorithms (`LinUCB` and `LinearTS`) and average the performance over multiple users (ie simulations)\n",
    "\n",
    "The regret $R(T) = \\sum_t \\phi_t^\\top (\\theta^\\star - \\theta_t)$\n",
    "\n",
    "The performance is the expected regret over multiple users. You can also test `LinearTS` without the additional $\\sqrt{d}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urKPGY9vXxRn"
   },
   "source": [
    "You can use `RandomLinearArms` to test your code before using Jester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1pezF4JUKKO"
   },
   "outputs": [],
   "source": [
    "# from mvarl_hands_on.utils.coldstart import RandomLinearArms\n",
    "\n",
    "nb_simulations = 4\n",
    "T = int(4e4)\n",
    "\n",
    "algorithms = {\n",
    "            'OFUL': lambda arm_features, bound_theta: \n",
    "              OFUL(arm_features=arm_features, reg_factor=1., delta=0.01,\n",
    "                 bound_theta=bound_theta, noise_std=config_cs['noise_std']),\n",
    "             'LinearTS': lambda arm_features, bound_theta:\n",
    "              LinearTS(arm_features=arm_features, reg_factor=1., delta=0.01,\n",
    "                 bound_theta=bound_theta, noise_std=config_cs['noise_std'])\n",
    "             }\n",
    "\n",
    "regrets = {}\n",
    "\n",
    "for alg_name in algorithms.keys():\n",
    "    if alg_name not in regrets.keys():\n",
    "        regrets[alg_name] = np.zeros((nb_simulations, T))\n",
    "    \n",
    "    for k in range(nb_simulations):\n",
    "        if k % 1 == 0:\n",
    "            print(\"{} simulation {}/{}\".format(alg_name, k+1, nb_simulations))\n",
    "        model = ColdStartFromDataset(**config_cs)\n",
    "#         model = RandomLinearArms()\n",
    "        alg = algorithms[alg_name](arm_features=, bound_theta=)\n",
    "\n",
    "        #TODO: implement interaction loop\n",
    "        #for t\n",
    "        #   ....\n",
    "        #   regrets[alg_name][k, t] = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vz5uoLmvUKKP"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for alg_name in regrets.keys():\n",
    "    data = np.cumsum(regrets[alg_name], axis=1)\n",
    "    n_rep, T = data.shape\n",
    "    \n",
    "    mean_regret = np.mean(data, axis=0)\n",
    "    std_regret = np.std(data, axis=0) / math.sqrt(n_rep)\n",
    "    t = np.arange(T)\n",
    "    plt.plot(t, mean_regret, label=alg_name)\n",
    "    plt.fill_between(t, mean_regret - 2 * std_regret, mean_regret + 2 * std_regret, alpha=0.15)\n",
    "plt.legend()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MVARL19_part3.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
