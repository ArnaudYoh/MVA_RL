{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsaXz-ENaLbx"
   },
   "source": [
    "# Exploration in Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HHhiMrobaW8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mvarl_hands_on'...\n",
      "remote: Enumerating objects: 39, done.\u001b[K\n",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 39 (delta 14), reused 37 (delta 12), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (39/39), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf mvarl_hands_on/\n",
    "!git clone https://github.com/rlgammazero/mvarl_hands_on.git\n",
    "!cd mvarl_hands_on/ && git fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jpzHHRYd0pI"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './mvarl_hands_on/utils')\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from gridworld import GridWorldWithPits\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQNxcIZtaSZJ"
   },
   "source": [
    "## Finite-Horizon Tabular MDPs\n",
    "We consider finite horizon problems with horizon $H$.For simplicity, we consider MDPs with stationary transitions and rewards, ie these functions do not depend on the stage ($p_h =p$, $r_h=r$ for any $h \\in [H]$).\n",
    "\n",
    "The value of a policy or the optimal value function can be computed using *backward induction*.\n",
    "\n",
    "\n",
    "Given a deterministic (non-stationary) policy $\\pi = (\\pi_1, \\pi_2, \\ldots, \\pi_H)$, backward induction applies the Bellman operator defined as\n",
    "$$\n",
    "V_h^\\pi(s) = \\sum_{s'} p(s'|s,\\pi_h(s)) \\left( r(s,\\pi_h(s),s') + V_{h+1}^\\pi(s')\\right)\n",
    "$$\n",
    "where $V_{H+1}(s) = 0$, for any $s$. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Suggestion:\n",
    "- $V$ -> $(H+1, S)$-dimensional matrix\n",
    "- deterministic policy $\\pi$ -> $(H, S)$-dimensional matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Smh0opCibDY1"
   },
   "source": [
    "**Question 1:** implement backward induction for $V^\\pi$ and $V^\\star$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhLaiao3aR4N"
   },
   "outputs": [],
   "source": [
    "def evaluate_policy(P, R, H, policy):\n",
    "    \"\"\"\n",
    "        Parameters:\n",
    "            P: transition function (S,A,S)-dim matrix\n",
    "            R: reward function (S,A,S)-dim matrix\n",
    "            H: horizon\n",
    "            policy: a deterministic policy (H, S)-dim matrix\n",
    "            \n",
    "        Returns:\n",
    "            The V-function of the provided policy\n",
    "    \"\"\"\n",
    "    S, A = P.shape[0], P.shape[1]\n",
    "    V = np.zeros((H+1, S))\n",
    "    for h in range(H-1, -1, -1):\n",
    "        for s in range(S):\n",
    "            a = policy[h, s]\n",
    "            for s_next in range(S):\n",
    "                V[h, s] += P[s, a , s_next] * (R[s, a, s_next] + V[h+1, s_next])\n",
    "    \n",
    "    return V\n",
    "\n",
    "def backward_induction(P, R, H):\n",
    "    \"\"\"\n",
    "        Parameters:\n",
    "            P: transition function (S,A,S)-dim matrix\n",
    "            R: reward function (S,A,S)-dim matrix\n",
    "            H: horizon\n",
    "            \n",
    "        Returns:\n",
    "            The optimal V-function\n",
    "            The optimal policy\n",
    "    \"\"\"\n",
    "    S, A = P.shape[0], P.shape[1]\n",
    "    \n",
    "    policy = np.full((H,S), -1)\n",
    "    V = np.zeros((H+1, S))\n",
    "    for h in reversed(range(H)):\n",
    "        for s in range(S):\n",
    "            expected_rewards = np.zeros(A)\n",
    "            for a in range(A):\n",
    "                expected = 0\n",
    "                for s_next in range(S):\n",
    "                    expected += P[s, a, s_next] * (R[s, a, s_next] + V[h+1, s_next])\n",
    "                expected_rewards[a] = expected\n",
    "            policy[h, s] = np.argmax(expected_rewards)\n",
    "            policy_action = policy[h, s] \n",
    "            for s_next in range(S):\n",
    "                V[h, s] += P[s, policy_action , s_next] * (R[s, policy_action, s_next] + V[h+1, s_next])\n",
    "                \n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_l6lqhDbYmQ"
   },
   "source": [
    "Let's set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkOs-0y_bd61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| : : :G|\n",
      "| :x: : |\n",
      "|\u001b[43mS\u001b[0m: : : |\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid1 = [\n",
    "    ['', '', '', 'g'],\n",
    "    ['', 'x', '', ''],\n",
    "    ['s', '', '', '']\n",
    "]\n",
    "grid1_MAP = [\n",
    "    \"+-------+\",\n",
    "    \"| : : :G|\",\n",
    "    \"| :x: : |\",\n",
    "    \"|S: : : |\",\n",
    "    \"+-------+\",\n",
    "]\n",
    "\n",
    "\n",
    "env = GridWorldWithPits(grid=grid1, txt_map=grid1_MAP, uniform_trans_proba=0)\n",
    "H = 6\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Paggla09bl6S"
   },
   "source": [
    "We should test previous functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgeanS2NbpQg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.98342174 3.98668316 3.99888469 3.99900565 3.93845103 3.38442821\n",
      "  3.98743386 3.99907706 3.91567934 3.95432206 3.99516932 3.99818051]\n",
      " [3.35518231 3.38566532 3.39841218 3.39933889 3.31201648 2.75064778\n",
      "  3.38668694 3.39869023 2.99900565 3.32685495 3.37162833 3.39692963]\n",
      " [2.73311111 2.762375   2.79823611 2.79966667 2.38934167 2.144975\n",
      "  2.76311944 2.79840833 2.39933889 2.38934167 2.74873056 2.77888611]\n",
      " [1.79966667 2.15083333 2.186      2.2        1.78983333 1.19\n",
      "  2.15733333 2.18616667 1.79966667 1.78983333 1.79966667 2.161     ]\n",
      " [1.2        1.19       1.58       1.6        1.19       0.6\n",
      "  1.19       1.58       1.2        1.19       1.2        1.2       ]\n",
      " [0.6        0.6        0.6        1.         0.6        0.\n",
      "  0.6        0.6        0.6        0.6        0.6        0.6       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]]\n",
      "[[3.98342174 3.98668316 3.99888469 3.99900565 3.93845103 3.38442821\n",
      "  3.98743386 3.99907706 3.91567934 3.95432206 3.99516932 3.99818051]\n",
      " [3.35518231 3.38566532 3.39841218 3.39933889 3.31201648 2.75064778\n",
      "  3.38668694 3.39869023 2.99900565 3.32685495 3.37162833 3.39692963]\n",
      " [2.73311111 2.762375   2.79823611 2.79966667 2.38934167 2.144975\n",
      "  2.76311944 2.79840833 2.39933889 2.38934167 2.74873056 2.77888611]\n",
      " [1.79966667 2.15083333 2.186      2.2        1.78983333 1.19\n",
      "  2.15733333 2.18616667 1.79966667 1.78983333 1.79966667 2.161     ]\n",
      " [1.2        1.19       1.58       1.6        1.19       0.6\n",
      "  1.19       1.58       1.2        1.19       1.2        1.2       ]\n",
      " [0.6        0.6        0.6        1.         0.6        0.\n",
      "  0.6        0.6        0.6        0.6        0.6        0.6       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "V_optimal, optimal_pol = backward_induction(env.P, env.R, H)\n",
    "print(V_optimal)\n",
    "Vpi = evaluate_policy(env.P, env.R, H, optimal_pol)\n",
    "print(Vpi)\n",
    "assert np.allclose(V_optimal, Vpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MACThGeMb48-"
   },
   "source": [
    "Run the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbyoa9Qpb6Yb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| : : :G|\n",
      "| :x: : |\n",
      "|\u001b[43mS\u001b[0m: : : |\n",
      "+-------+\n",
      "\n",
      "+-------+\n",
      "| : : :G|\n",
      "| :x: : |\n",
      "|S:\u001b[43m_\u001b[0m: : |\n",
      "+-------+\n",
      "  (right)\n",
      "+-------+\n",
      "| : : :G|\n",
      "| :x: : |\n",
      "|S: :\u001b[43m_\u001b[0m: |\n",
      "+-------+\n",
      "  (right)\n",
      "+-------+\n",
      "| : : :G|\n",
      "| :x: : |\n",
      "|S: : :\u001b[43m_\u001b[0m|\n",
      "+-------+\n",
      "  (right)\n",
      "+-------+\n",
      "| : : :G|\n",
      "| :x: :\u001b[43m_\u001b[0m|\n",
      "|S: : : |\n",
      "+-------+\n",
      "  (up)\n",
      "+-------+\n",
      "| : : :\u001b[42mG\u001b[0m|\n",
      "| :x: : |\n",
      "|S: : : |\n",
      "+-------+\n",
      "  (up)\n",
      "+-------+\n",
      "| : : :G|\n",
      "| :x: : |\n",
      "|\u001b[43mS\u001b[0m: : : |\n",
      "+-------+\n",
      "  (right)\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "env.render()\n",
    "for i in range(H):\n",
    "    next_state, reward, _, _ = env.step(optimal_pol[i, state])\n",
    "    env.render()\n",
    "    state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZtdzpwUcHYj"
   },
   "source": [
    "Finally we are ready to implement our exploration algorithm.\n",
    "\n",
    "**Question 2**: implement the **UCB-VI** algorithm.\n",
    "\n",
    "UCBVI is an algorithm for efficient exploration in finite-horizon tabular MDP.\n",
    "In this setting, the regret is defined as\n",
    "$$R(K) = \\sum_{k=1}^K V^\\star_1(s_{k,1}) - V^{\\pi_k}_1(s_{k,1})$$\n",
    "UCBVI enjoys a regret bound of order $O(\\sqrt{HSAK})$.\n",
    "\n",
    "The structure of the algorithm is as follow\n",
    "\n",
    "For $k = 1, \\ldots, K$ do<br>\n",
    "> Solve optimistic planning problem -> $(V_k, Q_k, \\pi_k)$<br>\n",
    "> Execute the optimistic policy $\\pi_k$ for $H$ steps<br>\n",
    ">> for $h=1, \\ldots, H$<br>\n",
    ">>> $a_{k,h} = \\pi(s_{k,h})$<br>\n",
    ">>> execute $a_{k,h}$, observe $r_{k,h}$ and $s_{k, h+1}$<br>\n",
    ">>> $N(s_{k,h}, a_{k,h}, s_{k,h+1}) += 1$ (update also estimated reward and transitions)\n",
    "\n",
    "<font color='#ed7d31'>Optimistic planning</font>\n",
    "\n",
    "UCBVI exploits exploration bonus to perform optimistic planning on the empirical MDP $(\\hat{p}, \\hat{r})$.\n",
    "The optimal Q-function of this MDP can be obtained using backward induction.\n",
    "\n",
    "The optimal Bellman operator for Q-function is defined similarly as\n",
    "$$\n",
    "Q_h^\\star(s,a) =  b(s,a) + \\sum_{s'} p(s'|s,a) \\left( r(s,a,s') + \\max_{a'} Q_{h+1}^\\star(s',a')\\right) \n",
    "$$\n",
    "where $Q_{H+1}(s,a) = 0$ and $b$ is an exploration bonus.\n",
    "\n",
    "<font color='#ed7d31'>Exploration Bonus</font>\n",
    "\n",
    "Using Hoeffding's bound we have that\n",
    "$$\n",
    "b_{k,h}(s,a) = 7(H-h+1)L\\sqrt{\\frac{1}{N_k(s,a)}}\n",
    "$$\n",
    "where $L = \\ln(5SAT/\\delta)$.\n",
    "\n",
    "A tighter exploration bonus is obtained using Bernstein's bound. Since it's expression is much more complicated, we provided the code (see `compute_bernstein_bonus`).\n",
    "\n",
    "\n",
    "Refer to [Minimax Regret Bounds for Reinforcement Learning](https://arxiv.org/abs/1703.05449) for additional details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXMJTmLPcOwS"
   },
   "outputs": [],
   "source": [
    "class UCBVI:\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        np.random.seed(seed=config['seed'])\n",
    "        self.env = config['env']\n",
    "        self.horizon = config['horizon']\n",
    "        self.scale_factor = config['scale_factor']\n",
    "        self.nb_repetitions = config['repetitions']\n",
    "        self.nb_episodes = config['episodes']\n",
    "        assert config['b_type'] in ['hoeffding', 'bernstein']\n",
    "        self.b_type = config['b_type']\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        S, A = self.env.Ns, self.env.Na\n",
    "        self.delta = 0.1\n",
    "        self.t = 0\n",
    "        self.episode = 0\n",
    "        self.episode_value = list()\n",
    "        self.Phat = np.zeros((S, A, S))\n",
    "        self.Rhat = np.zeros((S, A, S))\n",
    "        self.N_sa = np.zeros((S, A), dtype=np.int)\n",
    "        self.N_sas = np.zeros((S, A, S), dtype=np.int)\n",
    "        self.policy = np.ones((self.horizon, S), dtype=np.int)\n",
    "        self.V = np.zeros((self.horizon+1, S))\n",
    "        self.Q = np.zeros((self.horizon+1, S, A))\n",
    "        self.bonus = np.zeros((self.horizon, S, A))\n",
    "        \n",
    "    def get_optimistic_q(self):\n",
    "        \"\"\" Compute optimistic Q-function and associated greedy policy\n",
    "        \"\"\"\n",
    "        H = self.horizon\n",
    "        S, A = self.N_sa.shape\n",
    "        self.V.fill(0)\n",
    "        self.Q.fill(0)\n",
    "        for h in reversed(range(H)):\n",
    "            if self.b_type == 'hoeffing':\n",
    "                self.compute_hoeffding_bonus(h)\n",
    "            if self.b_type == 'bernstein':\n",
    "                self.compute_hoeffding_bonus(h)\n",
    "            for s in range(S):\n",
    "                expected_rewards = np.zeros(A)\n",
    "                for a in range(A):  \n",
    "                    if self.N_sa[s][a] > 0:\n",
    "                        expected = 0\n",
    "                        for s_next in range(S):\n",
    "                            expected += self.Phat[s,a,s_next] * (self.Rhat[s,a,s_next] + self.V[h+1,s_next])\n",
    "                        expected_rewards[a] = expected\n",
    "                        self.Q[h,s,a] = min(H, self.bonus[h,s,a] + expected)\n",
    "                    else:\n",
    "                        self.Q[h,s,a] = H\n",
    "                self.policy[h, s] = np.argmax(expected_rewards)\n",
    "                self.V[h,s] = min(H-h+2., self.V[h,s])   \n",
    "        #TODO\n",
    "                \n",
    "    def compute_hoeffding_bonus(self, h):\n",
    "        \"\"\"Compute Hoeffding-based exploration bonus\n",
    "        \"\"\"\n",
    "        S, A = self.N_sa.shape\n",
    "        H = self.horizon\n",
    "        T = H * self.nb_episodes\n",
    "        for s in range(S):\n",
    "            for a in range(A):\n",
    "                L = np.log(5 * S * A * T / self.delta)\n",
    "                n = np.sqrt(1 / max(self.N_sa[s][a], 1))\n",
    "                self.bonus[h,s,a] =  7(H - h + 1) * L * n\n",
    "        # TODO\n",
    "        \n",
    "    def compute_bernstein_bonus(self, h, Vhp1):\n",
    "        \"\"\"Compute Bernstein-based exploration bonus\n",
    "\n",
    "        Parameters:\n",
    "            h: state\n",
    "            Vhp1: value function at state h+1 (S-dim vector)\n",
    "        \"\"\"\n",
    "        S, A = self.N_sa.shape\n",
    "        for s in range(S):\n",
    "            for a in range(A):\n",
    "                L = np.log(5 * S * A * max(1, self.N_sa[s][a]) / self.delta)\n",
    "                n = max(1, self.N_sa[s][a])\n",
    "                var, mean = 0, 0\n",
    "                for i in range(S):\n",
    "                    mean += self.Phat[s,a,i] * Vhp1[i]\n",
    "                for i in range(S):\n",
    "                    var += self.Phat[s,a,i] * (Vhp1[i] - mean) * (Vhp1[i] - mean)\n",
    "                T1 = np.sqrt(8 * L * var / n) + 14 * L * (self.horizon -h + 2) / (3*n)\n",
    "                T2 = np.sqrt(8 * (self.horizon -h + 2)**2  / n)\n",
    "                self.bonus[h,s,a] = self.scale_factor * (T1 + T2)\n",
    "\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"Update the internal statistics\n",
    "        \"\"\"\n",
    "        self.N_sas[state, action, next_state] += 1\n",
    "        self.N_sa[state, action] += 1\n",
    "        self.Phat[state, action, next_state] = self.N_sas[state, action, next_state] / self.N_sa[state, action]\n",
    "        self.Rhat[state, action, next_state] = ((self.N_sas[state, action, next_state] -1) * self.Rhat[state, action, next_state] + reward) / self.N_sas[state, action, next_state]\n",
    "        \n",
    "        \n",
    "    def run_episode(self):\n",
    "        episode_reward = 0\n",
    "        state = self.env.reset()\n",
    "        initial_state = state\n",
    "        self.get_optimistic_q()\n",
    "        \n",
    "        Vpi = evaluate_policy(self.env.P, self.env.R, self.horizon, self.policy)\n",
    "        self.episode_value.append(Vpi[0, initial_state])\n",
    "        \n",
    "        for h in range(self.horizon):\n",
    "            action = self.policy[h, state]\n",
    "            next_state, reward, done, info = self.env.step(action)\n",
    "            self.update(state, action, reward, next_state)\n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "            self.t += 1\n",
    "        self.episode += 1\n",
    "        return initial_state, Vpi\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        # compute true value function (for the regret)\n",
    "        trueV, _ = backward_induction(self.env.P, self.env.R, self.horizon)\n",
    "        regret = np.zeros((self.nb_repetitions, self.nb_episodes+1))\n",
    "        for rep in range(self.nb_repetitions):\n",
    "            self.reset()\n",
    "            old_regret = 0\n",
    "            for k in range(self.nb_episodes):\n",
    "                init_state, Vpi = self.run_episode()\n",
    "                episode_regret = V_optimal[0, init_state] - Vpi[0, init_state]\n",
    "                old_regret += episode_regret\n",
    "                regret[rep, k+1] = old_regret\n",
    "        return regret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MoSaZ3xOckmd"
   },
   "source": [
    "Define the settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fjk1TbBock-G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current config is:\n",
      "{'b_type': 'hoeffding',\n",
      " 'env': <gridworld.GridWorldWithPits object at 0x7fb8d3a49550>,\n",
      " 'episodes': 4000,\n",
      " 'horizon': 6,\n",
      " 'repetitions': 5,\n",
      " 'scale_factor': 0.1,\n",
      " 'seed': 14}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'env': env,\n",
    "    'scale_factor': 0.1, # we use a scaling factor in order to increase the convergence speed\n",
    "    'seed': 14,\n",
    "    'horizon': H,\n",
    "    #'episodes': 4000,\n",
    "    'episodes': 4000,\n",
    "    'repetitions': 5,\n",
    "    'b_type': 'hoeffding' # [hoeffding, bernstein]\n",
    "}\n",
    "\n",
    "print(\"Current config is:\")\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSI7NR50cyFx"
   },
   "source": [
    "Run the agent and compare the behaviour with Hoeffding and Bernstein bound.\n",
    "\n",
    "A picture is automatically generated (it will show the regret average regret of the two algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8S3ObC9ncydR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb8d390ad50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "regret = {}\n",
    "for bound in ['hoeffding', 'bernstein']:\n",
    "    tmp_config = copy.copy(config) \n",
    "    tmp_config['b_type'] = bound\n",
    "    agent = UCBVI(config=tmp_config)\n",
    "    regret[bound] = agent.train()\n",
    "\n",
    "    mean_regret = np.mean(regret[bound], axis=0)\n",
    "    std = np.std(regret[bound], axis=0) / np.sqrt(regret[bound].shape[0])\n",
    "    x = np.arange(regret[bound].shape[1])\n",
    "    plt.plot(x, mean_regret, label=bound)\n",
    "    plt.fill_between(x, mean_regret + 2 * std, mean_regret - 2 * std, alpha=0.15)\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MVARL19_part4.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
